---
title: "Vietnam_NhaTrang"
author: "Nguyen Van Long"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(cache.lazy = FALSE,
                      tidy = "styler")
options(tinytex.engine = "xelatex")
```

\# Preparations

Load the necessary libraries

```{r}
#| label: libraries
#| output: false
#| eval: true
#| warning: false
#| message: false
#| cache: false

library(tidyverse)
library(easystats)
library(knitr)
library(sf)
library(rnaturalearth)
library(brms)
library(rstan)
library(tidybayes)
library(patchwork)
library(DHARMa)
library(HDInterval)
library(emmeans)
source('helperFunctions.R')
```

\# Read in the data

Now we will move to the raw \`nhatrang_data.csv\` data. There are many functions in R that can read in a CSV file. We will use a the \`read_csv()\` function as it is part of the tidyverse ecosystem.

```{r}
#| label: readData
dat_nt <- read_csv("../data/NhaTrangReefs.csv", trim_ws = TRUE)

#| label: readLabelset
labelset_nt <- read_csv("../data/NhaTrang_labelset.csv", trim_ws = TRUE) 
```

::: panel-tabset
\## glimpse

```{r}
#| label: examinData
dat_nt |> glimpse() 
```

\## head

```{r}
#| label: examinData1
## Explore the first 6 rows of the data
dat_nt |> head() 
```

\## str

```{r}
#| label: examinData2
dat_nt |> str() 
```

\## Easystats (datawizard)

```{r}
#| label: examinData3
dat_nt |> datawizard::data_codebook() |> knitr::kable()
```
:::

\# Data preparation

Before we can model these data, they need to be processed into a format compatible with statistical modelling. The necessary wrangling steps:

1.  exclude extraneous (unneeded) fields
2.  exclude poor images
3.  lengthen the data with respect to classification type
4.  join to a labelset lookup
5.  tally up the points per date/image/GROUP/type
6.  recode transect id
7.  fill in the gaps and add the zeros
8.  sum to transect level
9.  generate a Year field from the sample date

::: {.panel-tabset}

\## Exclude fields

Although it is often harmless enough to retain the other fields, it does make reviewing the data more combersum, so at an early stage within this exercise, we will probably restrict the data to just the above fields.

```{r}
#| label: selecting 

dat_nt <- dat_nt |>
  dplyr::select(
    site_id,
    site_name,
    site_latitude,
    site_longitude,
    site_depth,
    site_reef_name,
    site_code,
    survey_depth,
    survey_transect_number,
    survey_start_date,
    point_num,
    point_human_group_code
    )
dat_nt |> as.data.frame() |> head()
```

```{r}
dat_nt |> dim()
```



## Tally up points

Count the number of points of each type as well as sum up the total number of points per image.

```{r}
#| label: count
dat_nt <- 
  dat_nt |> 
  group_by(across(c(starts_with("site"),
    starts_with("survey"),
    point_human_group_code))
  ) |>
  summarise(COUNT = n(), .groups = "keep") |> 
  ungroup(point_human_group_code) |>
  mutate(TOTAL = sum(COUNT)) |>
  ungroup() 
dat_nt |> as.data.frame() |> head() 
```

## Recode transects

```{r}
#| label: recode_transects
dat_nt <- 
  dat_nt |>
  mutate(transect_id = paste0(site_name, survey_transect_number)) 
dat_nt |> as.data.frame() |> head() 
```

## Fill in any gaps

Since the data represent the classification of points in images, they only include what was present, not what was also absent. For example, if all five points are Algae, then this also means that all other functional groups are absent - yet this information is lacking in the data. For modelling purposes it is vital that we fill in all the zero values.

To do so, we must create a data set that contains every GROUP in every IMAGE.

```{r}
GROUPS <- dat_nt |> pull(point_human_group_code) |> unique()
data.filler <- dat_nt |>
  dplyr::select(
    starts_with("site"),
    survey_start_date,
    survey_depth,
    transect_id,
    TOTAL) |> 
  distinct() |> 
 tidyr::crossing(point_human_group_code = GROUPS) 

dat_nt <-
  dat_nt |> 
  full_join(data.filler) |>
  group_by(
    across(c(starts_with("site"),
      survey_start_date,
      #Year,
      survey_depth,
      transect_id,
     point_human_group_code
    ))) |> 
  mutate(COUNT = ifelse(is.na(COUNT), 0, COUNT),
    TOTAL = max(TOTAL, na.rm = TRUE)
  )
dat_nt |> as.data.frame() |> head() 
```



## Generate a year field

```{r}
#| label: mutateYear
dat_nt <-
  dat_nt |>
  mutate(Year = lubridate::year(survey_start_date),
    TropYear = lubridate::year(survey_start_date + months(3))
  ) 
dat_nt |> as.data.frame() |> head() 
```

## Declare all character vectors as categorical

We will also create a categorical version of year.

```{r}
#| label: declare factors
dat_nt <-
  dat_nt |>
  mutate(across(where(is.character), ~factor(.)))  |> 
  mutate(across(c(Year, TropYear),
                list(~factor(.)),
                .names = "f{.col}"))

dat_nt |> as.data.frame() |> head() 
```

::: panel-tabset
```{r}
#| label: EDA1
#| fig.width: 8
#| fig.height: 4
dat_nt |>
  filter(point_human_group_code == "HC") |> 
  ggplot(aes(y =  100*COUNT/TOTAL, x = survey_start_date)) +
  geom_point() +
  geom_line(aes(group = transect_id)) + 
  scale_y_continuous("Hard coral cover (%)") +
  scale_colour_discrete("Survey depth (m)") +
  scale_x_datetime("Year", date_breaks = "2 months", date_labels = "%b") +
  facet_wrap(~site_name) +
  theme_classic()
```

### Boxplots

```{r}
#| label: EDA2
#| fig.width: 4
#| fig.height: 4
dat_nt |>
  filter(point_human_group_code == "HC") |> 
  ggplot(aes(y =  100*COUNT/TOTAL, x = fYear)) +
  geom_boxplot() +
  facet_wrap(~site_name) 
```

I fully acknowledge this issue and therefore acknowledge that the analysis I will present is completely invalid.
:::

```{r, mhiden=TRUE}
#| label: hard coral
dat_hc_nt <- dat_nt |>
  filter(point_human_group_code == "HC") |>
  droplevels()
```

```{r}
dat_hc_nt |> head()
```

# Fit models

::: {.panel-tabset}

## Binomial model

$$
\begin{align}
y_{i} &\sim{} Bin(\pi_{i}, n_{i})\\
log\left(\frac{\pi_i}{1-\pi_i}\right) &= \beta_0 + \beta_{i}\mathbf{X}\\
\beta_0 \sim{} N(0, 1)\\
\beta_{1-3} \sim{} N(0, 1)\\
\end{align}
$$

:::: {.panel-tabset}

### Define priors

```{r}
dat_hc_nt |>
  mutate(COVER = COUNT/TOTAL) |>
  group_by(fYear) |>
  summarise(
    mean(qlogis(COVER), na.rm=TRUE),
    sd(qlogis(COVER), na.rm=TRUE))
```

```{r}
form <- bf(COUNT | trials(TOTAL) ~ fYear + (1|site_name) + (1|transect_id),
           family = binomial(link = "logit"))
```

```{r}
priors <- prior(normal(0, 2), class = "Intercept") +
  prior(normal(0, 1), class = "b") +
  prior(student_t(3, 0, 2), class = "sd")
```

```{r}
model1 <- brm(form,
data = dat_hc_nt,
prior = priors,
sample_prior = "only",
iter = 5000,
warmup = 1000,
chains = 3,
cores = 3,
thin = 5,
refresh = 0,
backend = "rstan")
```

```{r}
model1 |>
  conditional_effects() |>
  plot() |>
  _[[1]] +
  geom_point(data = dat_hc_nt, aes(y = COUNT/TOTAL, x = fYear), inherit.aes = FALSE)
```

```{r}
model1 <- update(model1, sample_prior = "yes")
```

```{r}
model1 |>
  conditional_effects() |>
  plot() |>
  _[[1]] +
  geom_point(data = dat_hc_nt, aes(y = COUNT/TOTAL, x = fYear), inherit.aes = FALSE)
```

```{r}
model1 |> SUYR_prior_and_posterior()
```

```{r}
model1$fit |> stan_trace()
```

```{r}
model1$fit |> stan_ac()
```

```{r}
model1$fit |> stan_rhat()
```

```{r}
model1$fit |> stan_ess()
```

```{r}
model1 |> pp_check(type = 'dens_overlay', ndraws = 100)
```

```{r}
resids <- model1 |> make_brms_dharma_res(integerResponse = FALSE)
```

```{r}
#| fig.width : 8
#| fig.height : 8
wrap_elements(~testUniformity(resids)) +
  wrap_elements(~plotResiduals(resids, form = factor(rep(1, nrow(dat_hc_nt))))) +
  wrap_elements(~plotResiduals(resids)) +
  wrap_elements(~testDispersion(resids))

```

```{r}

```

```{r}
model1 |> conditional_effects()
```

```{r}
model1 |> 
  as_draws_df() |> 
  summarise_draws(median, HDInterval::hdi, rhat, length, ess_bulk, ess_tail) |>
  knitr::kable()
  
```

```{r}

model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  regrid(trans = "log") |>
  pairs() |> 
  gather_emmeans_draws() |> 
  mutate(.value = exp(.value)) |> 
  summarise(median_hdci(.value), Pl = mean(.value <0), Pg = mean(.value >0))
  
```

```{r}
model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  gather_emmeans_draws() |> 
  summarise(median_hdci(.value), Pl = mean(.value <0), Pg = mean(.value >0)
            )
```

```{r}
model1 |>
  as_draws_df() |>
  dplyr::select(starts_with("b_")) |>
  mutate(across(everything(), exp)) |>
  summarise_draws(median,
                  hdi,
                  rhat,
                  length,
                  Pl = ~ mean(. < 1),
                  Pg = ~ mean(. > 1) 
                  ) |>
  knitr::kable()
```

```{r}
0.1677509/(1+0.1677509)
```

```{r}
model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  gather_emmeans_draws() |> 
  summarise(median_hdci(.value))
```

```{r}
model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  pairs() |> 
  gather_emmeans_draws() |> 
  summarise(median_hdci(.value),
            Pl=mean(.value<0),
            Pg = mean(.value >0))
```

```{r}
model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  regrid(trans="log") |> 
  pairs() |> 
  gather_emmeans_draws() |> 
    mutate(.value = exp(.value)) |> 
  summarise(median_hdci(.value),
            Pl=mean(.value<0),
            Pg = mean(.value >0))
```

```{r}
g1 <- model1 |> 
  emmeans(~fYear) |> 
  regrid() |> 
  gather_emmeans_draws() |> 
  summarise(median_hdci(.value)) |> 
  ggplot(aes(y = y, x = fYear)) +
  geom_pointrange(aes(ymin = ymin, ymax = ymax)) +
  theme_classic() +
  scale_y_continuous("Coral cover (%)", labels = scales::label_number(scale = 100)) +
  scale_x_discrete("Year")

ggsave(g1, file = "../output/honmuncover1.png", dpi = 300, width = 8, height = 6.5)
```

# Mapping Sites

# df location

```{r}
data_only_location_nt <- dat_hc_nt |>
  dplyr::select(site_name, site_latitude, site_longitude) |>
  distinct()
data_only_location_nt <- data_only_location_nt |>
  st_as_sf(coords = c("site_longitude", "site_latitude"), remove = FALSE, crs = 4326)
```

```{r}
vn <- rnaturalearth::ne_countries(scale = 10, country = "Vietnam", returnclass = "sf")
```

```{r}
reefs <- read_sf("../data/GIS/reef_500_poly.shp")
```

```{r}
library(maps)
cities <- world.cities |> filter (country.etc =="Vietnam")
```

```{r}
bbox <- st_bbox(c(xmin = 109.0,ymin = 12.0, xmax =109.5,  ymax =12.5), crs =4326)
bbox1 <- st_bbox(vn)
map_overlay <-  ggplot() +
  geom_sf(data = vn) +
  geom_sf(data = reefs, fill = "lightblue") +
  #geom_point(data = cities, aes(y = lat, x = long)) +   
  #geom_text(data = cities, aes(y = lat, x = long - 0.05, label = name), hjust = 1) +
  geom_sf(data = st_as_sfc(bbox), fill = "blue", alpha = 0.5) +
  #ggspatial::annotation_north_arrow(location = "tr") +   
  #ggspatial::annotation_scale() +  
  coord_sf(xlim = bbox1[c("xmin","xmax")], ylim = bbox1[c("ymin","ymax")]) +  
  theme_bw()+  
  theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())
map_overlay
```

```{r}
map1 <-   
  ggplot() +   
  geom_sf(data = vn) +  
  geom_sf(data = reefs, fill = "lightblue") +
  geom_sf(data = data_only_location_nt) +  
  #geom_point(data = cities, aes(y = lat, x = long)) +   
  geom_text(data = cities, aes(y = lat, x = long - 0.05, label = name), hjust = 1) + 
  ggspatial::annotation_north_arrow(location = "tr") + 
  ggspatial::annotation_scale() +  
  coord_sf(xlim = bbox[c("xmin","xmax")], ylim = bbox[c("ymin","ymax")]) +  
  theme_bw()+  
  theme(axis.title = element_blank())
map1
```

```{r}
map1 + inset_element(map_overlay, 
                     left = 0.6, 
                     right = 0.9,
                     top = 0.6, 
                     bottom = 0.01)
```

```{r}
map_site <- map1 + map_overlay
map_site
```

```{r}
ggsave(map_site, file = "../output/honmun_site.png", dpi = 300, width = 8, height = 4)
```
